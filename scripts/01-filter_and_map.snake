# snakemake -p --use-conda --cluster 'qsub -V -cwd -j y -S /bin/bash -pe mpi {threads} -o {log}' --jobs 120 --latency-wait 200
# File:     Snakefile
# Name:     Neal Platt
# Date:     26 March 2018
# Desc:     This Snake file is used to filter, map, and call SNPs on exome data from
#           Schistosoma Haemotobium made available through the Anderson lab at Texas
#           Biomedical Research Institute.  
# Usage:    snakemake -p --use-conda --cluster 'qsub -V -cwd -j y -S /bin/bash -pe mpi {threads} -o {log}' --jobs 10 --latency-wait 200
# Reqs:     BWA
#           Trimmomatic
#           SAMtools
#           GATK
# Comments: 
#
#       VERY IMPORTANT NOTE:
#       Sometimes the cluster has a difficult time with latency issues
#       make sure that snakemake is run with the following option:
#
#                     --latency-wait 120
#       
#       a latency time greater than 120 is OK when in doubt
#
#-------------------------------------------------------------------------------
# To Do:
#   4] fix messages - seem to crash when running 
#   6] whatup with all the snakejob* files
#   7] download genome and raw data from ncbi
#   8] sub-workflows for major stages
#  10] Param errors on samse/pe_sort
#-------------------------------------------------------------------------------

#setting up snakemake 
configfile: "config.yaml"
HOME_DIR = "/master/nplatt/schisto_hybridization/"
CONTIG_CHUNKS=50
ASSEMBLY = "schHae_v1.fa"

#setting work directory
RESULTS_DIR = HOME_DIR + "results/"
DATA_DIR = HOME_DIR + "data/"
LOG_DIR = RESULTS_DIR + "logs/"
GENOME_DIR = DATA_DIR + "genome/"
GENOME = GENOME_DIR + ASSEMBLY
SEQ_DIR = DATA_DIR + "sequence_data/"
FILTER_READS_DIR = RESULTS_DIR + "01-filtered_reads/"
MAP_DIR = RESULTS_DIR + "02-mapped_reads/" 
BQSR_DIR = RESULTS_DIR + "03-gatk_bqsr/" 
BQSR_R1_DIR = BQSR_DIR + "r1/"
BQSR_R2_DIR = BQSR_DIR + "r2/"
GENO_DIR = RESULTS_DIR + "04-genotype/" 
WGA_DIR = RESULTS_DIR + "06-wga/" 

#setting work directory
workdir: HOME_DIR

#setting up local rules to be run on the head node
localrules: all
localrules: create_list_of_contigs
localrules: bqsr_r1_prep_gdbimport
localrules: bqsr_r2_prep_gdbimport

#list of all the sample IDs to be processed - eventually put in the config file
HAE_SAMPLES = [ "Sh.NE_Dai-002.1",      "Sh.NE_Dai-010.1",      "Sh.NE_Dai-013.3",      
            	"Sh.NE_Dai-031.1",      "Sh.NE_Dai-033.1",      "Sh.NE_Dai-044.1",
            	"Sh.NE_Dai-045.1",      "Sh.NE_Dai-051.1",      "Sh.NE_Dai-074.1",      
            	"Sh.NE_Dai-146.1",      "Sh.NE_DaiCP-233.1",    "Sh.NE_DaiCP-276.1", 
           	    "Sh.NE_DaiCP-277.2",    "Sh.NE_Doki-029.1",     "Sh.NE_Kar-001.1",      
            	"Sh.NE_Kar-002.1",      "Sh.NE_Kar-076.1",      "Sh.NE_Kar-096.2",      
            	"Sh.NE_Kar-241.1",      "Sh.NE_Kar-241.2",      "Sh.NE_Kar-281.1",
            	"Sh.NE_Kar-37.2",       "Sh.NE_Lata-007.3",     "Sh.NE_Lata-033.1", 
            	"Sh.NE_Lata-078.1",     "Sh.NE_Lata-253.1",     "Sh.NE_Lata-275.2",
            	"Sh.NE_Lata-293.1",     "Sh.NE_Lata-294.1",     "Sh.NE_LibTB-009.2",
            	"Sh.NE_LibTB-010.1",    "Sh.NE_LibTB-022.1",    "Sh.NE_LibTB-028.1",    
            	"Sh.NE_LibTB-031.1",    "Sh.NE_NG-011.1",       "Sh.NE_NG-06.2", 
            	"Sh.NE_NG-089.1",       "Sh.NE_NG-236.1",       "Sh.NE_Seb-076.1",
            	"Sh.NE_Seb-078.2",      "Sh.NE_Seb-081.2",      "Sh.NE_Tiag-272.1",
            	"Sh.NE_YK-029.2",       "Sh.NE_YK-069.1",       "Sh.NE_YK-099.2",
            	"Sh.NE_YK-248.2",       "Sh.NE_Youri-069.2",    "Sh.NE_Youri-091.3", 
            	"Sh.TZ_PEM0063.1",      "Sh.TZ_PEM0075.1",      "Sh.TZ_PEM0076.1",
            	"Sh.TZ_PEM0079.1",      "Sh.TZ_PEM0089.2",      "Sh.TZ_PEM0094.2",      
            	"Sh.TZ_PEM0099.2",      "Sh.TZ_PEM0103.1",      "Sh.TZ_PEM0104.1",
            	"Sh.TZ_PEM0106.2",      "Sh.TZ_PEM0108.1",      "Sh.TZ_PEM0110.1", 
            	"Sh.TZ_PEM0114.3",      "Sh.TZ_PEM0115.4",      "Sh.TZ_PEM0120.1",
            	"Sh.TZ_PEM0125.1",      "Sh.TZ_PEM0126.1",      "Sh.TZ_PEM0127.1",
            	"Sh.TZ_PEM0128.1",      "Sh.TZ_PEM0130.1",      "Sh.TZ_PEM0133.1",
            	"Sh.TZ_PEM0139.2",      "Sh.TZ_PEM0145.3",      "Sh.TZ_PEM0154.1", 
            	"Sh.TZ_PEM0157.3",      "Sh.TZ_PEM0166.1",      "Sh.TZ_PEM0171.1",
            	"Sh.TZ_UNG0006.1",      "Sh.TZ_UNG0038.1",      "Sh.TZ_UNG0076.1",
            	"Sh.TZ_UNG0077.1",      "Sh.TZ_UNG0078.1",      "Sh.TZ_UNG0087.2",
           	    "Sh.TZ_UNG0089.3",      "Sh.TZ_UNG0092.3",      "Sh.TZ_UNG0099.1", 
            	"Sh.TZ_UNG0102.1",      "Sh.TZ_UNG0111.1",      "Sh.TZ_UNG0117.1",
            	"Sh.TZ_UNG0121.1",      "Sh.TZ_UNG0125.3",      "Sh.TZ_UNG0127.1",
            	"Sh.TZ_UNG0129.2",      "Sh.TZ_UNG0134.1",      "Sh.TZ_UNG0137.3",
            	"Sh.TZ_UNG0139.1",      "Sh.TZ_UNG0142.2",      "Sh.TZ_UNG0146.1"]

HAE_SRA_SAMPLES = ["ERR084970", "ERR037800", "SRR433865"]
MAN_SAMPLES     = ["Sm.BR_1278.1", "Sm.BR_0447.1", "Sm.BR_2039.1"]
BOV_SAMPLES     = ["ERR119622", "ERR103048"]
CUR_SAMPLES     = ["ERR119623"]
#Curassoni samples ERR310937 download constantly fails
EXOME_SAMPLES = HAE_SAMPLES + MAN_SAMPLES
SRA_SAMPLES = HAE_SRA_SAMPLES + CUR_SAMPLES + BOV_SAMPLES
SAMPLES = HAE_SAMPLES + HAE_SRA_SAMPLES + MAN_SAMPLES + CUR_SAMPLES + BOV_SAMPLES

#prep array to split genome
NUMBERS=list(range(1, CONTIG_CHUNKS))
NUMS_2D=[]
for NUM in NUMBERS:
    NUMS_2D.append("%02d" % NUM)

#get genomes - sman_v7 ftp://ftp.sanger.ac.uk/pub/project/pathogens/Schistosoma/mansoni/v7/sequence/Smansoni_v7.fa.gz
shell.prefix("source ~/.bash_profile; ")

#-------------------------------------------------------------------------------
# clean all of the snake files created from previous run
onstart:
    shell("rm snakejob.*")

#-------------------------------------------------------------------------------
# initializing rule - these files need to be generated...initiates the pipeline
rule all:
    input: 
        expand(MAP_DIR + "{sample}_processed.bam", sample=SAMPLES) 

#-------------------------------------------------------------------------------
# Filter reads
#
rule filter_reads:
    input:
        R1 = SEQ_DIR + "{sample}_R1.fastq.gz",
        R2 = SEQ_DIR + "{sample}_R2.fastq.gz"
    output:
        R1_PE = FILTER_READS_DIR + "{sample}_filtered_paired_R1.fastq.gz",
        R1_SE = temp(FILTER_READS_DIR + "{sample}_filtered_unpaired_R1.fastq.gz"),
        R2_PE = FILTER_READS_DIR + "{sample}_filtered_paired_R2.fastq.gz",
        R2_SE = temp(FILTER_READS_DIR + "{sample}_filtered_unpaired_R2.fastq.gz"),
        RX = FILTER_READS_DIR + "{sample}_filtered_unpaired_RX.fastq.gz"
    threads:
        12
    conda:
        "environment.yaml"
    log:
        LOG_DIR + "{sample}.filter_reads.log"    
    shell:
        """
        trimmomatic \
            PE \
            -threads {threads} \
            -phred33 \
            {input.R1} \
            {input.R2} \
            {output.R1_PE} \
            {output.R1_SE} \
            {output.R2_PE} \
            {output.R2_SE} \
            LEADING:10 \
            TRAILING:10 \
            SLIDINGWINDOW:4:15 \
            MINLEN:36

        zcat {output.R1_SE} {output.R2_SE} | gzip >{output.RX} 
        """

#-------------------------------------------------------------------------------
# MAPPING FILTERED READS TO THE GENOME
#
rule index_genome:
    input:
        GENOME_DIR + "GCA_000699445.1_SchHae_1.0_genomic.fna"
    output:
        expand(GENOME_DIR + "schHae_v1.fa{ext}", ext=["", ".pac", ".ann", ".amb", ".bwt", ".sa"])
    conda:
        "environment.yaml"
    log:
        LOG_DIR + "index_genome.log"
    params:
        SOFT_LINK = GENOME
    shell:
        """
        ln -s {input} {params.SOFT_LINK}
                
        bwa index {params.SOFT_LINK}
        """

rule bwa_map_R1:
    input:
        rules.index_genome.output,
        PE_R1 = rules.filter_reads.output.R1_PE,
        REFERENCE = GENOME
    output:
        temp(MAP_DIR + "{sample}_R1.sai")
    conda:
        "environment.yaml"
    threads:
        12
    log:
        LOG_DIR + "{sample}.bwa_map_R1.log"
    shell:
        """
        bwa aln -t {threads} -f {output} {input.REFERENCE} {input.PE_R1}
        """

rule bwa_map_R2:
    input:
        rules.index_genome.output,
        PE_R2 = rules.filter_reads.output.R2_PE,
        REFERENCE = GENOME
    output:
        temp(MAP_DIR + "{sample}_R2.sai")
    conda:
        "environment.yaml"
    threads:
        12
    log:
        LOG_DIR + "{sample}.bwa_map_R2.log"
    shell:
        """
        bwa aln -t {threads} -f {output} {input.REFERENCE} {input.PE_R2}
	    """

rule bwa_map_RX:
    input:
        rules.index_genome.output,
        SE_RX = rules.filter_reads.output.RX,
        REFERENCE = GENOME
    output:
        temp(MAP_DIR + "{sample}_RX.sai")
    conda:
        "environment.yaml"
    threads:
        12
    log:
         LOG_DIR + "{sample}.bwa_map_RX.log"
    shell:
        """
        bwa aln -t {threads} -f {output} {input.REFERENCE} {input.SE_RX}
        """

rule bwa_sampe:
    input:
        REFERENCE = GENOME,
        SAI_R1 = rules.bwa_map_R1.output,
        SAI_R2 = rules.bwa_map_R2.output,
        PE_R1 = rules.filter_reads.output.R1_PE,
        PE_R2 = rules.filter_reads.output.R2_PE,
    output:
        temp(MAP_DIR + "{sample}_samPE.bam")
    conda:
        "environment.yaml"
    threads:
        12
    log:
        LOG_DIR + "{sample}.bwa_sampe.log"
    shell:
        """
        bwa sampe {input} | samtools view -Sb -F 4 - >{output}       
        """

rule bwa_samse:
    input:
        REFERENCE = GENOME,
        SAI_RX = rules.bwa_map_RX.output,
        SE_RX = rules.filter_reads.output.RX
    output:
        temp(MAP_DIR + "{sample}_samSE.bam")
    conda:
        "environment.yaml"
    threads:
        12
    log:
        LOG_DIR + "{sample}.bwa_samse.log"
    shell:
        """
        bwa samse {input} | samtools view -Sb -F 4 - >{output}       
        """

rule sort_sampe:
    input:
        rules.bwa_sampe.output
    output:
        temp(MAP_DIR + "{sample}_samPE_sorted.bam")
    conda:
        "environment.yaml"
    threads:
        12
    log:
        LOG_DIR + "{sample}.sort_sampe.log"
    shell:
        """
        samtools sort -o {output} {input} 
        """

rule sort_samse:
    input:
        rules.bwa_samse.output
    output:
        temp(MAP_DIR + "{sample}_samSE_sorted.bam")
    conda:
        "environment.yaml"
    threads:
        12
    log:
        LOG_DIR + "{sample}.sort_samse.log"
    shell:
        """
        samtools sort -o {output} {input} 
        """

rule process_bam:
    input:
        rules.sort_sampe.output,
        rules.sort_samse.output
    output:
        MERGED = temp(MAP_DIR + "{sample}_merged.bam"),
        RGS = temp(MAP_DIR + "{sample}_merged_RGs.bam"),
        BAM = protected(MAP_DIR + "{sample}_processed.bam"),
        METRICS = MAP_DIR + "{sample}_noDupes.metrics",
        INDEX = MAP_DIR + "{sample}_processed.bam.bai"
    conda:
        "environment.yaml"
    threads:
        12
    log:
        LOG_DIR + "{sample}.process_bam.log"
    params:
        CELL = lambda wildcards: config['rg_cell'][wildcards.sample],
        LANE = lambda wildcards: config['rg_lane'][wildcards.sample],
        INDEX = lambda wildcards: config['rg_index'][wildcards.sample]
    shell:
        """
        samtools merge {output.MERGED} {input}

        singularity exec snpCalling_v0.0.8.img \
            gatk AddOrReplaceReadGroups \
                --INPUT={output.MERGED} \
                --OUTPUT={output.RGS} \
                --RGID={params.CELL}.{params.LANE} \
                --RGLB=library1 \
                --RGPL=illumina \
                --RGPU={params.CELL}.{params.INDEX}.{params.LANE} \
                --RGSM={wildcards.sample}

        singularity exec snpCalling_v0.0.8.img \
            gatk MarkDuplicates \
                --INPUT {output.RG} \
                --OUTPUT {output.BAM} \
                --METRICS_FILE {output.METRICS} \
                --MAX_FILE_HANDLES_FOR_READ_ENDS_MAP 900

        samtools index {output.BAM}
        """



