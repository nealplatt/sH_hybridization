# File:     04-pop_stats.snake
# Name:     Neal Platt
# Date:     13 April 2018
# Desc:     This Snake file is used to generate sH vcfs with sM coordinates and
#           calculate basic popgen stats including struture plots, pca, fst,etc.

# Reccomended
# Usage:    snakemake \
#               --printshellcmds \
#               --use-conda \
#               --cluster 'qsub -V -cwd -S /bin/bash -pe mpi {threads} -o {log}.log -e {log}.stderr' \
#               --jobs 100 \
#               --latency-wait 200 \
#               --snake \
#               --keep-going
#               --restart-times 2

# Reqs:     All required software should be installed/available through the 
#           singularity image, packaged conda env, or in the scripts dir.

# Comments: This portion of the workflow exectures after refining the genotypes

#-------------------------------------------------------------------------------
# To Do:
#   3] update comments
#   4] add cleanup on success
#   5] would prefer to run structure rather than admixture.
#   6] Add R code for building plots
#   7] mitochondrial PCA
#-------------------------------------------------------------------------------

#setting up snakemake 
configfile: "config.yaml"
HOME_DIR = "/master/nplatt/schisto_hybridization/"
CONTIG_CHUNKS=50
ASSEMBLY = "schHae_v1.fa"

#setting work directory
RESULTS_DIR = HOME_DIR + "results/"
SCRIPTS_DIR = HOME_DIR + "scripts/"
DATA_DIR = HOME_DIR + "data/"
LOG_DIR = RESULTS_DIR + "logs/"
GENOME_DIR = DATA_DIR + "genome/"
GENOME = GENOME_DIR + ASSEMBLY
SEQ_DIR = DATA_DIR + "sequence_data/"
FILTER_READS_DIR = RESULTS_DIR + "01-filtered_reads/"
MAP_DIR = RESULTS_DIR + "02-mapped_reads/" 

GATK_DIR = RESULTS_DIR + "03-genotype_sH/" 
BQSR_R1_DIR = GATK_DIR + "r1/"
R1_HC = BQSR_R1_DIR + "hc/"
R1_DB = BQSR_R1_DIR + "db/"
R1_GENO = BQSR_R1_DIR + "geno/"
R1_MERGE = BQSR_R1_DIR + "merge/"
R1_FILTER = BQSR_R1_DIR + "filter/"
R1_BAM = BQSR_R1_DIR + "bams/"
R1_TABLE = BQSR_R1_DIR + "tables/"

BQSR_R2_DIR = GATK_DIR + "r2/"
R2_HC = BQSR_R2_DIR + "hc/"
R2_DB = BQSR_R2_DIR + "db/"
R2_GENO = BQSR_R2_DIR + "geno/"
R2_MERGE = BQSR_R2_DIR + "merge/"
R2_FILTER = BQSR_R2_DIR + "filter/"
R2_BAM = BQSR_R2_DIR + "bams/"
R2_TABLE = BQSR_R2_DIR + "tables/"

GENO_DIR = GATK_DIR + "filter_geno/"
 
OUTGENO_DIR = RESULTS_DIR + "04-genotype_outgroups/"
OUTGENO_HC = OUTGENO_DIR + "hc/"
OUTGENO_DB = OUTGENO_DIR + "db/"
OUTGENO_GENO = OUTGENO_DIR + "geno/"
OUTGENO_MERGE = OUTGENO_DIR + "merge/"
OUTGENO_FILTER = OUTGENO_DIR + "filter/"

################################################################################
HAE_SRA_SAMPLES = ["ERR084970", "ERR037800", "SRR433865"]
MAN_SAMPLES     = ["Sm.BR_1278.1", "Sm.BR_0447.1", "Sm.BR_2039.1"]
BOV_SAMPLES     = ["ERR119622", "ERR103048"]
CUR_SAMPLES     = ["ERR119623", "ERR310937"]
#Curassoni samples ERR310937 download constantly fails
#removed the following bovis sample just to much data "ERR103048"

OUTGROUP_SAMPLES = MAN_SAMPLES + CUR_SAMPLES + BOV_SAMPLES

NUMBERS=list(range(1, CONTIG_CHUNKS))
NUMS_2D=[]
for NUM in NUMBERS:
    NUMS_2D.append("%02d" % NUM)

FIRST_MERGE=list(range(1, 1000))
FIRST_MERGE_3D=[]
for NUM in FIRST_MERGE:
    FIRST_MERGE_3D.append("%03d" % NUM)

SECOND_MERGE=list(range(1, 100))
SECOND_MERGE_2D=[]
for NUM in SECOND_MERGE:
    SECOND_MERGE_2D.append("%02d" % NUM)


#setting work directory
workdir: HOME_DIR

#setting up local rules to be run on the head node
localrules: all

shell.prefix("source ~/.bash_profile; ")

#-------------------------------------------------------------------------------
# initializing rule - these files need to be generated...initiates the pipeline
rule all:
    input:
        expand(POPSTATS_DIR + "sH_filtered_{chr_type}-variants_sManLift.vcf", chr_type=["auto", "sex", "mito", "all"])

rule call_snps_in_outgroup_samples:
    input: 
        GENOME_DIR + "schHae_v1.dict"
        MAP_DIR + "{sample}_processed.bam.bai",
        BAM = MAP_DIR + "{sample}_processed.bam",
        REFERENCE = GENOME,
        LIST = GATK_DIR + "contigs.{chunk}.list"
    output:
        OUTGENO_HC + "{sample}_n{chunk}.g.vcf"
    threads:
        1
    log:
        LOG_DIR + "{sample}_{chunk}.call_snps_in_outgroup_samples"
    shell:
        """
        singularity exec snpCalling_v0.0.8.img \
            gatk HaplotypeCaller \
               -I {input.BAM} \
                -O {output} \
                -R {input.REFERENCE} \
                -L {input.LIST} \
                -ERC GVCF
        """

#combine the snp calls into single vcfs per individuals
rule build_outgroup_individual_vcfs:
    input: 
        expand(OUTGENO_HC + "{{sample}}_n{number}.g.vcf", number=NUMS_2D) 
    output:
        SORTED_VCF = OUTGENO_HC + "{sample}.sorted.g.vcf",
        LIST = OUTGENO_HC + "{sample}.list",
        TMP_VCF = OUTGENO_HC + "tmp_{sample}.merged.g.vcf"
    threads:
       1
    log:
        LOG_DIR + "{sample}.build_outgroup_individual_vcfs"
    shell:
        """
        ls {input} >{output.LIST}
    
        singularity exec snpCalling_v0.0.8.img \
           gatk MergeVcfs \
                -I {output.LIST} \
                -O {output.TMP_VCF}
        
        singularity exec snpCalling_v0.0.8.img \
            gatk SortVcf \
                -I {output.TMP_VCF} \
                -O {output.SORTED_VCF}
        """

#make a list and db for gatk gdbimport
rule prep_for_gdbimport_of_outgroup_snps:
    input:
        expand(R1_HC + "{sample}.sorted.g.vcf", sample=SAMPLES)
    output:
        LIST = OUTGENO_HC + "hc_samples.list",
        DB = OUTGENO_DB
    threads:
        1
    log:
       LOG_DIR + "prep_for_gdbimport_of_outgroup_snps"
    shell:
        """
        ls {input} >{output.LIST}
	    mkdir {output.DB}
	    """

#run gdbimport (per contig)
rule gdbimport_of_outgroup_snps:
    input:
        OUTGENO_HC + "hc_samples.list",
    output:
        OUTGENO_DB + "{contig}"
    threads:
        12
    log:
        LOG_DIR + "{contig}.gdbimport_of_outgroup_snps"
    #params:
    #    CONTIG=config["contigs"]
    shell:
        """
        singularity exec snpCalling_v0.0.8.img \
            gatk --java-options \"-Xmx4g -Xms4g\" GenomicsDBImport \
                -V {input} \
                --genomicsdb-workspace-path {output} \
                -L {wildcards.contig} \
                --reader-threads {threads} \
                --batch-size 24
        """
  
#genotype each contg
rule genotype_outgroup_samples:
    input:
        REFERENCE = GENOME,
        DB = OUTGENO_DB + "{contig}"     
    output:
        OUTGENO_GENO + "{contig}.vcf"
    threads:
        1
    log:
        LOG_DIR + "{wildcards.contig}.genotype_outgroup_samples"
    shell:
        """
        singularity exec snpCalling_v0.0.8.img \
            gatk GenotypeGVCFs \
                -R {input.REFERENCE} \
                -V gendb://{input.DB} \
                -new-qual \
                -O {output}
        """

#create a cohort.vcf of raw genotypes through heirarchical merging.
# first merge vcfs into a single file per thousand contigs
#   create a lists to merge
rule prep_to_merge_1k_outgroup_vcfs:
    input:
        expand(OUTGENO_GENO + "{contig}.vcf", contig=config['contigs'])
    output:
        expand(OUTGENO_MERGE + "merge-1_{number}.list", number=FIRST_MERGE_3D)
    threads:
        1
    log:
        LOG_DIR + "create_list_of_outgroup_samples_to_merge"
    params:
        GENO_DIR = OUTGENO_GENO,
        PREFIX = OUTGENO_MERGE + "merge-1_",
        VCF_LIST = OUTGENO_MERGE + "vcf.list"
    shell:
        """     
        for VCF in $(ls {params.GENO_DIR}*.vcf); do
            echo $VCF
        done >{params.VCF_LIST}
        
        singularity exec snpCalling_v0.0.8.img \
            split -n l/999 \
                --numeric-suffixes=1 \
                --additional-suffix .list \
                {params.VCF_LIST} \
                {params.PREFIX}
        """

# merge to 1k vcfs
rule merge_1k_outgroup_vcfs:
    input:
        LIST = OUTGENO_MERGE + "merge-1_{number}.list"
    output:
        OUTGENO_MERGE + "merge-1_{number}.vcf"
    threads:
        12
    log:
        LOG_DIR + "n{number}.merge_1k_outgroup_vcfs"
    shell:
        """        
        singularity exec snpCalling_v0.0.8.img \
           gatk MergeVcfs \
                -I {input.LIST} \
                -O {output}
        """

rule prep_to_merge_100_outgroup_vcfs:
    input:
        expand(OUTGENO_MERGE+ "merge-1_{number}.vcf", number=FIRST_MERGE_3D)
    output:
        expand(OUTGENO_MERGE + "merge-2_{number}.list", number=SECOND_MERGE_2D)
    threads:
        1
    log:
        LOG_DIR + "prep_to_merge_100_outgroup_vcfs"
    params:
        GENO_DIR = OUTGENO_GENO,
        PREFIX = OUTGENO_MERGE + "merge-2_",
        VCF_LIST = OUTGENO_MERGE + "vcf.list"
    shell:
        """     
        for VCF in $(ls {params.GENO_DIR}*.vcf); do
            echo $VCF
        done >{params.VCF_LIST}
        
        singularity exec snpCalling_v0.0.8.img \
            split -n l/99 \
                --numeric-suffixes=1 \
                --additional-suffix .list \
                {params.VCF_LIST} \
                {params.PREFIX}
        """

## merge to 100 vcfs
rule merge_100_outgroup_vcfs:
    input:
        LIST = OUTGENO_MERGE + "merge-2_{number}.list"
    output:
        OUTGENO_MERGE + "merge-2_{number}.vcf"
    threads:
        12
    log:
        LOG_DIR + "n{number}.merge_100_outgroup_vcfs"
    shell:
        """        
        singularity exec snpCalling_v0.0.8.img \
           gatk --java-options "-Xmx8g" MergeVcfs \
                --MAX_RECORDS_IN_RAM 500000 \
                -I {input.LIST} \
                -O {output}
        """


## combine 1k vcfs into a single cohort vcf
rule build_outgroup_cohort_vcf:
    input:
        VCF = expand(OUTGENO_MERGE + "merge-2_{number}.vcf", number=SECOND_MERGE_2D)
    output:
        OUTGENO_FILTER + "cohort_raw.vcf"
    threads:
        12
    log:
        LOG_DIR + "build_outgroup_cohort_vcf"
    params: 
        LIST = OUTGENO_FILTER + "contig.list",
        TMP_VCF = OUTGENO_FILTER + "all.merged.g.vcf"
    shell:
        """        
        ls {input} >{params.LIST}
    
        singularity exec snpCalling_v0.0.8.img \
           gatk --java-options "-Xmx8g" MergeVcfs \
                --MAX_RECORDS_IN_RAM 500000 \
                -I {params.LIST} \
                -O {params.TMP_VCF}
        
        singularity exec snpCalling_v0.0.8.img \
            gatk --java-options "-Xmx8g" SortVcf \
                --MAX_RECORDS_IN_RAM 500000 \
                -I {params.TMP_VCF} \
                -O {output}
        """
